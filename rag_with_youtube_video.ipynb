{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k0XEyamB3Jq"
      },
      "source": [
        "# Example of RAG with a Youtube video\n",
        "\n",
        " we download the trascription of a Youtube video and use an LLM for extracting information from that video.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbYkZcRPB3Js"
      },
      "source": [
        "### Install the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29Dfd09SB3Ju"
      },
      "outputs": [],
      "source": [
        "!pip3 install langchain\n",
        "!pip3 install langchain_pinecone\n",
        "!pip3 install langchain[docarray]\n",
        "!pip3 install docarray\n",
        "!pip3 install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfL0YPJ5B3Jw"
      },
      "outputs": [],
      "source": [
        "!pip3 install youtube_transcript_api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLwOhib4B3Jx"
      },
      "source": [
        "# Let's download an example transcript from a YT video\n",
        "\n",
        "You can change the id of the video to download other video transcriptions.\n",
        "We save the contect to a file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_C3t8YQB3Jy"
      },
      "outputs": [],
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "srt = YouTubeTranscriptApi.get_transcript(\"pxiP-HJLCx0\") # CHANGE THE ID OF THE VIDEO\n",
        "\n",
        "with open(\"./files/youtube_transcription.txt\", \"a\") as file:\n",
        "    for i in srt:\n",
        "        file.write(i['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcPMWxE4B3J0"
      },
      "source": [
        "# Select the LLM model to use\n",
        "\n",
        "The model must be downloaded locally to be used, so if you want to run llama3, you should run:\n",
        "\n",
        "```\n",
        "\n",
        "ollama pull llama3\n",
        "\n",
        "```\n",
        "\n",
        "Check the list of models available for Ollama here: https://ollama.com/library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id51nepwB3J1"
      },
      "source": [
        "# We instantiate the model and the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQmMhuEZB3J2"
      },
      "outputs": [],
      "source": [
        "#MODEL = \"gpt-3.5-turbo\"\n",
        "#MODEL = \"mixtral:8x7b\"\n",
        "#MODEL = \"gemma:7b\"\n",
        "#MODEL = \"llama2\"\n",
        "MODEL = \"llama3\" # https://ollama.com/library/llama3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Low9wy2RB3J2"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import Ollama\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "\n",
        "model = Ollama(model=MODEL)\n",
        "embeddings = OllamaEmbeddings(model=MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUIW9mdqB3J3"
      },
      "source": [
        "# We load the transcription previously saved using TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOsRfS-aB3J4"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"./files/youtube_transcription.txt\")\n",
        "text_documents = loader.load()\n",
        "text_documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UUDS1mdB3J4"
      },
      "source": [
        "# We explit the document into chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TGS4SubB3J5"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "text_documents = text_splitter.split_documents(text_documents)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEGpA2r5B3J5"
      },
      "outputs": [],
      "source": [
        "text_documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCANBs3mB3J6"
      },
      "source": [
        "# Store the PDF in a vector space.\n",
        "\n",
        "From Langchain docs:\n",
        "\n",
        "`DocArrayInMemorySearch is a document index provided by Docarray that stores documents in memory. It is a great starting point for small datasets, where you may not want to launch a database server.`\n",
        "\n",
        "The execution time of the following block depends on the complexity and longitude of the PDF provided. Try to keep it small and simple for the example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LxIzlMfB3J6"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "vectorstore = DocArrayInMemorySearch.from_documents(text_documents, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXbjwSNAB3J7"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRrNMGbnB3J7"
      },
      "source": [
        "# We instantiate the parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjPcO8a3B3J7"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUVl27Z1B3J8"
      },
      "source": [
        "# Generate the conversation template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQez488FB3J8"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Answer the question based on the context below. If you can't\n",
        "answer the question, answer with \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt.format(context=\"Here is some context\", question=\"Here is a question\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO78LYKiB3J8"
      },
      "source": [
        "# We can now extract the information from the video!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avL2ET_mB3J9"
      },
      "outputs": [],
      "source": [
        "retrieved_context = retriever.invoke(\"laptop\")\n",
        "questions = [\n",
        "    \"Which is the best laptop for students?\",\n",
        "    \"How much is a laptop worth?\",\n",
        "    \"Make a summary of the video\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    formatted_prompt = prompt.format(context=retrieved_context, question=question)\n",
        "    response_from_model = model.invoke(formatted_prompt)\n",
        "    parsed_response = parser.parse(response_from_model)\n",
        "\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {parsed_response}\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}